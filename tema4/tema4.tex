\renewcommand{\tt}{t}
\newcommand{\yy}{y}
\newcommand{\yn}{{\yy_n}}
\newcommand{\ynn}{{\yy_{n+1}}}
\newcommand{\ta}{a}
\newcommand{\tb}{b}
\newcommand{\tn}{{\tt_n}}
\newcommand{\tnn}{{\tt_{n+1}}}
\newcommand{\ycero}{{y_a}}
\newcommand{\sol}{y}
\newcommand{\lipschitz}{Lipschitz\xspace}
\newcommand{\globLipschitz}{$y$--\lipschitz}
\newcommand{\locLipschitz}{localmente $y$--\lipschitz}

\chapter[Problemas de valor inicial para EDOs de primer orden]
{Problemas de valor inicial para ecuaciones diferenciales de primer
  orden%
  \footnote{\licenseInfo}}

Son muy numerosos los problemas (con orígenes diversos como la física,
química, biología o economía) que se formulan matemáticamente en
términos de ecuaciones diferenciales, es decir, ecuaciones cuya
incógnita, una función $y(x)$, describe un fenómeno dado a través de
una ley que relaciona a esta función con sus derivadas. La formulación
adecuada de esta ley junto a algunos datos adicionales (condiciones
iniciales) garantizarán el buen planteamiento del problema.

Este tema se centra en la resolución numérica de problemas de valor
inicial (o problemas de Cauchy) asociados a ecuaciones diferenciales
ordinarias (EDO). Este tipo de problemas se escriben de la siguiente
forma:
\begin{equation}
  \label{eq:pvi}
  \tag{PVI}
  \left\{
  \begin{aligned}
    &y' = f(\tt,\yy), \quad \tt\in[\ta,\tb],
    \\
    &y(\ta) = \ycero,
  \end{aligned}
  \right.
\end{equation}
donde la función (continua) $f:[\ta,\tb]\times\Rset\to\Rset$ y el
estado inicial $\ycero\in\Rset$ son datos conocidos. En el próximo
tema se estudia el caso general, donde
$f:[\ta,\tb]\times\Rset^n\to\Rset^n$ e $\ycero\in\Rset^n$, con
$n\in\Nset$. En numerosos problemas de la ciencia y la ingeniería, la
variable $\tt$ representa el tiempo aunque no siempre es necesario que
sea así. Con frecuencia hablaremos de $\tt$ como la <<variable
temporal>>).

\begin{definition}
  Llamamos solución de~\eqref{eq:pvi} a toda función $\sol\in
  C^1([\ta,\tb])$ tal que $\sol'(\tt)=f(\tt,\sol(\tt))$ para todo
  $\tt\in[\ta,\tb]$ y además $\sol(\ta)=\ycero$.\label{def:3}
\end{definition}

Obsérvese que, según esta definición, el
concepto de solución tiene un sentido global (en todo el intervalo
$[a,b]$), no local (en un entorno de $\ta$).
Como paso previo a la resolución numérica de~\eqref{eq:pvi}, deberemos
garantizar que el problema~\eqref{eq:pvi} está bien planteado, es
decir asegurar la existencia y unicidad de solución en el sentido
anterior. 

\section{Resultados teóricos preliminares}
\label{sec:tema4:resultados-teoricos}

Antes de comenzar a estudiar métodos numéricos para la resolución de
problemas de valor inicial, recordaremos en esta sección algunos
resultados teóricos relacionados con la existencia y unicidad de
solución del problema de Cauchy~(\ref{eq:pvi}), que han sido adaptados
a las necesidades de las siguientes secciones y serán dados sin
demostración. La clave en estos resultados será el analizar si la
función $f(x,y)$ es verifica la condición de Lipschitz que se define a
continuación:

\begin{definition}
  \label{def:lipschitz}
  Decimos que una función $f(\tt,y)$ verifica la condición de
  \resaltar{Lipschitz uniformemente} (o globalmente) respecto a $y$ en
    $[\ta,\tb]$ (o simplemente que $f$ es \globLipschitz)
    si existe $L>0$ tal que
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L |y-z|, \quad \forall \tt\in [\ta,\tb],
    \quad  \forall y,z\in \Rset.
  \end{equation*}
  Decimos que una función $f(\tt,y)$ verifica la condición de
  \resaltar{Lipschitz localmente} respecto a $y$ en
  $[\ta,\tb]$ (o que $f$ es \locLipschitz) si para todo compacto
  $K\subset\Rset$ existe $L_K>0$ tal que
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L_K |y-z|, \quad \forall \tt\in [\ta,\tb],
    \quad  \forall y,z\in K.
  \end{equation*}
\end{definition}

Antes del siguiente comentario, fijaremos la siguiente
\textbf{notación}: $\dy f$ designará a la derivada parcial de $f$
respecto a $y$, es decir $\dy f(\tt,y) = \frac{\partial f}{\partial
  \yy}(\tt,y)$. Para el resto de las variables se usarán notaciones
similares.
\begin{remark}
  En la práctica, para estudiar si una función es (local o
  globalmente) Lipschitz se suelen usar las siguientes condiciones
  suficientes:
  \begin{enumerate}
  \item Si $\dy f$ es continua en $[\ta,\tb]\times\Rset$, entonces $f$
    es \locLipschitz.
  \item Si además $\dy f$ está acotada en
    $[\ta,\tb]\times\Rset$, entonces $f$ es uniformemente
    \globLipschitz.
  \end{enumerate}
  Comprobaremos la segunda de estas afirmaciones (la primera se
  demuestra de forma análoga, usando que $\dy f$ está acotada
  en todo compacto $K\subset\Rset)$.
  Si $\dy f$ es continua en $[\ta,\tb]\times\Rset$, entonces en cada
  <<instante>> $t\in[\ta,\tb]$ la función
  $$\dy f(t,\cdot):\Rset \to \Rset$$
  es continua. Aplicando el teorema del valor medio, se tiene que
  dados $y$, $z\in\Rset$ existe $y^*$ entre $y$ y $z$ tal que
  \begin{equation*}
    |f(\tt,y)-f(\tt,z)| = |\dy f(\tt,y^*) \cdot (y-z)|.
  \end{equation*}
  Como además  $\dy f$ está acotada, existe $L>0$ tal que $|\dy
  f(\tt,y)|\le L$ para todo $(\tt,y)\in [\ta,\tb]\times\Rset$ y
  entonces 
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L |y-z|.
  \end{equation*}
\end{remark}

\begin{example}
  La función $$f(x,y)=y^2$$ es \locLipschitz en cualquier intervalo
  $[\ta,\tb]$, pues su derivada parcial $\dy f(x,y)=2y$ es continua. Sin
  embargo, esta función no está acotada cuando $y\in\Rset$, por lo que
  no tenemos garantías de que $f(x,y)$ sea uniformemente \globLipschitz.
  
  Veamos que realmente $f(x,y)$ no es a uniformemente \globLipschitz,
  comprobando que para cualquier constate $L>0$, podemos encontrar dos
  valores, $y_L$, $z_L\in\Rset$ de forma que
  \begin{equation*}
  |f(\tt,y_L)-f(\tt,z_L)| >  L  |y_L-z_L|.
 \end{equation*}
 Por ejemplo, dada $L>0$ podemos tomar $y_L=L$ y $z_L=0$, así el
 primer miembro es
 \begin{align*}
   |f(\tt,y_L)-f(\tt,z_L)|&=|L+0|\cdot |L-0|=4L^2,
   \intertext{mientras que el segundo miembro resulta} 
   L|y_L-z_L|&=2L^2<4L^2.
 \end{align*}
\end{example}

A continuación, presentamos los resultados teóricos fundamentales. El
primer Teorema utiliza hipótesis más débiles (\locLipschitz), aunque
sin alcanzar directamente la existencia y unicidad de solución en todo
$[a,b]$.  El Teorema~\ref{thm:existencia-unif-lipschitz} garantiza la
existencia y unicidad de solución de~\eqref{eq:pvi} en $[a,b]$,
aunque a costa de imponer una hipótesis muy fuerte (Lipschitz
uniforme), que reduce considerablemente el rango de problemas
diferenciales abarcados.
\begin{theorem}
  \label{thm:existencia-loc-lipschitz}
  Sea $f$ continua en $[\ta,\tb]\times\Rset$ y \locLipschitz. Entonces, para
  cualquier inicialización $\ycero\in\Rset$:
  \begin{enumerate}
  \item Existe una única solución local (definida en
    $[\ta,\ta+\varepsilon]$ para algún $\varepsilon>0$) y existe una
    única solución maximal (es decir, definida en todo $[a,b]$ o bien
    en $[\ta,c)\subset[\ta,\tb]$, para algún $c\in(\ta,\tb)$, y no
    prolongable a $\tt>c$) de~\eqref{eq:pvi}.
  \item Además: o bien la solución maximal $\sol(\tt)$  está definida en todo
    $[\ta,\tb]$, o bien ésta explota en tiempo finito (es decir existe
    $c\in (\ta,\tb)$ tal que $\lim_{\tt\to c^-} \sol(\tt) = \infty$).
  \end{enumerate}
\end{theorem}

\begin{theorem}[Picard]
  \label{thm:existencia-unif-lipschitz}
  Sea $f$ continua en $C^0([\ta,\tb]\times\Rset$ y (globalmente) \globLipschitz.
  Entonces, para cualquier inicialización $\ycero\in\Rset$, existe una
  única solución de~\eqref{eq:pvi}, que está definida en todo el
  intervalo $[\ta,\tb]$.% Además, para todo $\tt\in[\ta,\tb]$
  % se tiene la siguiente desigualdad:
  % \begin{equation*}
  %   |y(\tt)-y(\ta)| \le (\tb-\ta) \Big( \max_{\tt\in[\ta,\tb]}
  %     f(\tt,y(\ta))\Big) e^{L(\tt-\ta)}.
  % \end{equation*}
\end{theorem}

En lo que sigue, estudiaremos el análisis numérico de problemas
diferenciales en los que, en principio, la función $f(\tt,y)$ es tan
solo \locLipschitz. Por lo tanto el estudio de la existencia de
solución en $[\ta,\tb]$ no será una tarea inmediata. Usando el
Teorema~\ref{thm:existencia-loc-lipschitz}, intentaremos demostrar que
la solución maximal del problema~(\ref{eq:pvi}) está acotada en
$[\ta,\tb]$ y por tanto no explota en tiempo finito en este intervalo,
garantizando así existencia y unicidad de solución en $[\ta,\tb]$ (ver
en el ejemplo~\ref{ex:existencia-unicidad-loc-lipschitz}). Con este
propósito, recordamos ahora algunas propiedades interesantes de las
ecuaciones diferenciales que nos resultarán de gran utilidad.

\begin{proposition}[Algunas propiedades de las soluciones de~(\ref{eq:pvi})]
\label{pro:propiedades-pvi}
  Bajo las hipótesis del teorema~\ref{thm:existencia-loc-lipschitz}
  ($f$ \locLipschitz):
  \begin{enumerate}
  \item Sean $\sol_1(\tt)$ y $\sol_2(\tt)$ las soluciones de dos
    problemas del tipo~\eqref{eq:pvi} para la \textbf{misma ecuación
    diferencial} $y'=f(\tt,y)$ pero con \textbf{distintas condiciones
    iniciales}, es decir:
    $$\sol_1(\ta)<\sol_2(\ta)$$ 
    Entonces las gráficas de $\sol_1$ e $\sol_2$ no se cortan en
    ningún punto. En concreto, si $\sol_1$ y $\sol_2$ están
    definidas, respectivamente, en los intervalos $I_1$ e $I_2$,
    entonces
    \begin{equation*}
      \sol_1(\tt) < \sol_2(\tt), \quad \forall \tt \in I_1
      \cap I_2.
    \end{equation*}
    
  \item Sean $\sol_1(\tt)$ y $\sol_2(\tt)$ las soluciones de dos
    problemas del tipo~\eqref{eq:pvi} con la \textbf{misma condición
      inicial} pero con \textbf{ecuaciones diferenciales distintas},
    $y'=f_1(\tt,y)$ $y'=f_2(\tt,y)$. Si
    $$
    f_1(\tt,y) \le f_2(\tt,y) \quad \forall \tt\in[\ta,\tb], \quad
    \forall y\in\Rset,
    $$
    entonces
    $$
    \sol_1(\tt)\le \sol_2(\tt) \quad \forall \tt \in
    I_1 \cap I_2.
    $$
  \end{enumerate}
\end{proposition}

\begin{example}
  \renewcommand{\tt}{x}
  \label{ex:existencia-unicidad-loc-lipschitz}
  Estudiaremos la existencia y unicidad de solución del siguiente
  problema de valor inicial: 
  \begin{equation*}
    \left\{
      \begin{aligned}
        &y' = -y^2+2y\,\cos \tt, \quad \tt\in [0,2],\\
        &y(0)=1.
      \end{aligned}
    \right.
  \end{equation*}
  En primer lugar, $f(x,y)=-y^2+2y\,\cos \tt$ y $\dy f(t,y)=-2y+2\cos
  t$ son continuas en $[0,2]\times\Rset$, luego $f$ es \locLipschitz,
  por lo que (según el teorema~\ref{thm:existencia-loc-lipschitz})
  existe una única solución maximal, a la que denominaremos
  $\sol(\tt)$, definida en $I=[0,2]$ o bien en $I=[0,c)$ con
  $c<2$. Pero esta última posibilidad no se verifica, pues entonces
  $\sol(\tt)$ explotaría en $c$, pero veremos a continuación que
  $\sol(\tt)$ está acotada:
  \begin{enumerate}
  \item Sea $\sol_1$ la solución del problema de valor inicial para la
    misma ecuación diferencial pero para la condición inicial
    $y(0)=0$. Está claro que su única solución es $\sol_1(\tt)=0$
    para todo $\tt\in\Rset$. Y como $0=\sol_1(0)<\sol(0)=1$, entonces
    (según la proposición~\ref{pro:propiedades-pvi}, parte 2) podemos
    asegurar que $\sol$ está acotada inferiormente:
    \begin{equation*}
      0=\sol_1(\tt)<\sol(\tt), \quad \forall \tt\in I.
    \end{equation*}
  \item Sea ahora $f_2(\tt,y)=-y^2+2y$. Como $\cos\tt \le 1$  (y como
    ya podemos suponer $y>0$):
    $$f(\tt,y)=-y^2+2y\cos\tt \le -y^2+2y = f_2(\tt,y)\quad
    \forall \tt\in I, \forall y\in\Rset^+.$$ 
    Ahora podemos calcular
    directamente la solución $\sol_2$ del problema de valor inicial
    $y'=f_2(\tt,y)$, $y(0)=1$ (ya que la ecuación es autónoma),
    obteniendo:
    $$
    \sol_2(\tt)=\frac{2e^{2\tt}}{1+e^{2\tt}},
    $$
    función continua y por tanto acotada superiormente en $[0,2]$.
    Según la proposición~\ref{pro:propiedades-pvi} (parte 1)
    \begin{equation*}
      \sol(\tt)\le\sol_2(\tt)
    \end{equation*}
    y por tanto $\sol(\tt)$ está también acotada superiormente en
    $[0,2]$. Por lo tanto, $\sol$ está definida en todo $[0,2]$.
  \end{enumerate}
  \renewcommand{\tt}{t}
\end{example}

\section{El método de Euler}

A partir de ahora, nuestro objetivo será la descripción, análisis e
implementación de distintos métodos numéricos para la aproximación de
la solución de~\eqref{eq:pvi}. Estos métodos partirán con la
definición de una partición del intervalo $[\ta,\tb]$, formada por
$N+1$ puntos:
\begin{equation*}
  \ta=\tt_0 < \tt_1 < \cdots < \tt_N=\tb.
\end{equation*}
Por simplicidad, supondremos que la partición es uniforme, es decir,
\begin{equation*}
  \text{ si } h=\frac{b-a}{N}, \quad \text{entonces} \quad
  \tt_n=\ta+n\cdot h,\quad \forall n=0\dots,N
\end{equation*}
(en particular, $\tt_0=a$ y $\tt_N=b$). A continuación procedemos como
sigue:
\begin{enumerate}
\item Usamos el dato inicial $y_a$ para arrancar el método numérico,
  definiendo $y_0=y_a$ (más generalmente, $y_0\approx y_a$)
\item Seguidamente definimos una sucesión de forma que $y_{n+1}$ se
  calcula a partir de $y_n$ (y posiblemente de $y_{n-1}$, ...,
  $y_{n-k}$ para algún $k\ge 1$), con el fin de que
  $y_n\approx\sol(\tn)$. 
\end{enumerate}
Nuestro objetivo será que el método sea \textit{convergente}, en el
sentido de que la solución aproximada $\{\yn\}_n$ ``converja a la
solución exacta'' $\{\sol(\tn)\}_n$ cuando $h\to 0$. Íntimamente
relacionados con la convergencia están los conceptos de
``\textit{estabilidad}'' y ``\textit{consistencia}'', que estudiaremos
más adelante.
% \begin{enumerate}
% \item El método es \textit{consistente}, si la solución exacta
%   $\{\sol(\tn)\}_n$ ``verifica aproximadamente'' el esquema
%   numérico
% \item El método es \textit{estable} si ``responde continuamente'' a
%   perturbaciones en los datos iniciales.
% \end{enumerate}
% Más adelante distinguiremos entre métodos de un paso, en los que
% para calcular $y_{n+1}$ utilizamos solamente de $y_n$ y métodos
% multipaso, en los que  $y_{n+1}$ depende de los datos en varias etapas
% anteriores ($y_{n}$, $y_{n-1}$, ..., $y_{n-k}$ para algún $k\ge 1$.)

El método más sencillo es el de Euler (más precisamente, el método
de Euler explícito):
\begin{equation}
\label{eq:metodo-euler}
\left\{
\begin{aligned}
  &y_0 = \ycero, \\
  &y_{n+1} = \yn + h f(\tn, \yn), \quad n=0,\dots,N-1.
\end{aligned}
\right.
\end{equation}

Este método admite varias interpretaciones:

\subsection{Interpretaciones del método de Euler}

\subsubsection*{Interpretación geométrica}
En la ecuación $y(\tt)'=f(\tt,y(\tt))$ se puede interpretar que
$f(\tt,y(\tt))$ marca la pendiente (la derivada) de la solución,
$\sol(\tt)$ en cada instante $\tt\in [\ta,\tb]$.

\begin{center}
  \begin{graficaTikz}[width=23em, height=17em]
    \begin{axis}[ \axisXYmiddle, xtick=\empty, ytick=\empty, legend
      pos = north east, xlabel=$t$ ]
      % Draw a curve
      \addplot[domain=1.3:3.3, blue, ultra thick] {20+x*x*x*x};
      \addplot[domain=1.5:3.1, red, thick] {36+32*(x-2)};
      % Plot a label at curve root
      \node[coordinate, medium dot, 
            pin={[fill=blue!10!white]120:{\scriptsize $\sol(\tn)$}}] at
            (axis cs:2,36) {}; 
      \node[coordinate, medium dot, blue,
            pin={[fill=blue!10!white]120:{\scriptsize $\sol(\tt_{n+1})$}}] at
            (axis cs:2.7,73.144) {}; 
      % \node[coordinate, medium dot, blue, pin=100:{\scriptsize
      %   $\sol(\tt_{n+1})$}] at (axis cs:2.7,73.144) {};
      \addplot[dashed] coordinates {(2,7) (2,36)};
      \addplot[dashed] coordinates {(2.7,7) (2.7,58.4)};
      \node[coordinate, medium dot, pin=-30:{$y_{n}$}] at
      (axis cs:2,36) {}; 
      \node[coordinate, medium dot, pin=-30:{$y_{n+1}$}] at
      (axis cs:2.7,58.4) {}; 
      % Draw the name of curve
      \legend {$y(t)$};
    \end{axis}
  \end{graficaTikz}
\end{center}

Por tanto, suponiendo que $\yn$ es una buena aproximación de
$\sol(\tn)$ (por simplificar, $\yn=\sol(\tn)$):
\begin{enumerate}
\item Calculamos la recta, $r$, que pasa por $(\tn,\yn)$ y tiene pendiente
  $f(\tt_n, \yn)$:
  $$
  r(\tt) = \yn +  f(\tt_n, \yn) (\tt-\tt_n).
  $$
\item Calculamos $y_{n+1}$ como la ordenada de esta recta en
  $\tt=\tt_{n+1}$ es decir:
  $$
  y_{n+1} = r(\tt_{n+1}) = 
  \yn +  f(\tt_n, \yn) (\tt_{n+1}-\tt_n) = \yn +  f(\tt_n, \yn) \cdot h.
  $$
\end{enumerate}
Así obtenemos el método de Euler~\eqref{eq:metodo-euler}.

\subsubsection*{Desarrollo de Taylor}

Suponiendo que $\sol(t)$ (la solución exacta de~(\ref{eq:pvi})) es de
$C^2([\ta,\tb])$, podemos hacer su desarrollo de Taylor en $\tn$:
\begin{equation*}
  \sol(\tnn)=\sol(\tn+h) = \sol(\tn) + h\sol'(\tn) + \frac{h^2}{2} y''(\xi),
\end{equation*}
donde $\xi\in(\tn,\tnn)$. Como $\sol''$ está acotada, el último
término (el resto) será despreciable cuando $h$ es suficientemente
pequeño (pues contiene el factor $h^2$):
\begin{align}
  \label{eq:euler.taylor.1}
  \sol(\tnn)&\approx \sol(\tn) + h\sol'(\tn),
  \intertext{es decir,}
  \notag
  \sol(\tnn)&\approx \sol(\tn) + h f(\tn,y(\tn)),
  \intertext{y aproximando $\sol(\tn)\approx \yn$, $\sol(\tnn)\approx\ynn$:}
  \notag
  \ynn &\approx \yn + h f(\tn,\tn).
\end{align}

\paragraph{Notación.}
En lo que sigue, se utilizará la siguiente notación (derivada discreta
de $\ynn$):
\begin{equation}
  \label{eq:derivada-discreta}
  \ddt\ynn = \frac{\ynn-\yn}{h}.
\end{equation}
La ecuación~(\ref{eq:euler.taylor.1}) significa que 
$$\ddt\ynn\approx \sol(\tnn)$$
y usando esta notación, el método de Euler se puede escribir como
\begin{equation*}
  \ddt\ynn = f(\tn,\yn).
\end{equation*}

Utilizando distintas aproximaciones de $y'$ se podrían haber expuesto
ahora algunas variantes del método de Euler, pero éstas serán
introducidas a través de fórmulas de integración.

\subsubsection*{Integración numérica}
La solución exacta de~(\ref{eq:pvi}) puede escribirse de la siguiente
forma (formulación integral de la solución de~(\ref{eq:pvi})):
\begin{equation*}
  \sol(t) = \sol(\ta) + \int_\ta^t f(s,\sol(s))\, ds.
\end{equation*}
Tomando $a=\tn$, $t=\tnn$:
\begin{equation*}
  \sol(\tnn) = \sol(\tn) + \int_\tn^\tnn f(s,\sol(s))\, ds.
\end{equation*}
Para obtener el método de Euler implícito aproximamos la última
integral mediante la siguiente fórmula de cuadratura (regla
rectangular izquierda):
\begin{equation*}
  \int_a^b g(s)\,ds \approx hg(a), \quad \text{ con $h=b-a$}.
\end{equation*}
Aplicándola en el intervalo $[\tn,\tnn]$ para la formulación integral
anterior,
\begin{equation*}
  \ynn =  \yn + h f(\tn,\yn),
\end{equation*}
con $\yn\approx\sol(\tn)$, $\ynn\approx\sol(\tnn)$.

\subsubsection*{Algunas variantes del método de Euler.}

Utilizando otras fórmulas de cuadratura, se obtienen métodos numéricos
distintos al de Euler explícito. Por ejemplo:
\begin{enumerate}
\item Aproximando $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla
  rectangular derecha,
  \begin{equation*}
    \int_a^b g(s)\,ds \approx hg(b)
  \end{equation*}
  se obtiene el \textit{Método de Euler implícito} (implícito debido a
  que $\ynn$ no puede calcularse explícitamente, pues aparece en el
  segundo miembro)
  \begin{equation}
    \label{eq:euler-implicito}
    \tag{EI}
    \left\{
    \begin{aligned}
      &y_0=\ycero,\\ &\ynn = \yn + h f(\tn,\ynn).
    \end{aligned}
    \right.
  \end{equation}
\item Aproximando $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla del
  punto medio (que tiene orden mayor que las reglas rectangular
  derecha e izquierda):
  \begin{equation*}
    \ynn = \yn + h \; f(\tt_{n+1/2},\sol(\tt_{n+1/2})).
  \end{equation*}
  \begin{enumerate}
  \item Si aproximamos seguidamente $\sol(\tt_{n+1/2})$ por
    $\frac12\big(\sol(\tn)+\sol(\tnn)\big)$, se tiene el siguiente
    método implícito, conocido como método de \textit{Crank-Nicolson}
    (primera versión):
    \begin{equation}
    \label{eq:crank-nicolson-1}
      \tag{CN$_1$}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\ 
          &\ynn = \yn + h \; f\big(\tt_{n+1/2},\; \frac{\yn+\ynn}{2}\big).
        \end{aligned}
      \right.
    \end{equation}
  \item  Si aproximamos $\sol(\tt_{n+1/2})$ por
    $\sol(\tn)+\frac{h}{2}f(\tn,\sol(\tn))$ se llega al método explícito
    conocido como de \textit{Euler--Cauchy} o \textit{Euler modificado}:
    \begin{equation}
      \label{eq:euler-cauchy}
      \tag{EC}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\ 
          &\ynn = \yn + h \; f\big(\tt_{n+1/2},\;
          \yn+\frac{h}{2}f(\tn,\yn) \big).
        \end{aligned}
      \right.
    \end{equation}
  \end{enumerate}
\item Si aproximamos $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla
  del trapecio se llega al siguiente método (segunda variante del
  método de Crank-Nicolson):
  \begin{equation}
    \label{eq:crank-nicolson-1}
    \tag{CN$_2$}
    \left\{
      \begin{aligned}
        &y_0=\ycero,\\ 
        &\ynn = \yn + \frac h2 \; \big\{f(\tn,\;\sol(\tn))+f(\tnn,\;\sol(\tnn))\big\}.
      \end{aligned}
      \right.
    \end{equation}
    Si además aproximamos $\sol(\tnn)$ por
    $\sol(\tn)+hf(\tn,\sol(\tn))$ se llega al método explícito
    conocido como de \textit{Euler mejorado} (o \textit{método de Heunn}):
    \begin{equation}
      \label{eq:euler-mejorado}
      \tag{EM}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\
          &\ynn = \yn + h \; f\big(\tnn,\;
          \yn+h f(\tn,\yn) \big).
        \end{aligned}
      \right.
    \end{equation}
\end{enumerate}
Estas variantes del método de Euler se pueden escribir en una notación
algo más sencilla (y más cercana a la ecuación diferencial original),
utilizando la derivada discreta definida
en~\eqref{eq:derivada-discreta}. Por ejemplo, el método de Euler
implícito~\eqref{eq:euler-implicito} se sintetiza en:
\begin{equation*}
  y_0=\ycero,\quad \ddt\ynn = f(\tnn,\ynn).
\end{equation*}


\section{Error y convergencia en el método de Euler}
\label{sec:convergencia-euler}


\section{Métodos de Taylor. Métodos de Runge-Kutta}
\label{sec:metodos-de-taylor}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../apuntes-MNII.tex"
%%% End: 